{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "9VG9bgGQ5-a6"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from gensim.models import Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data into a pandas DataFrame\n",
        "df = pd.read_csv(\"Anime_data.csv\")\n",
        "df =df.dropna()\n",
        "\n",
        "# Convert the genre, producer and studio values into lists\n",
        "df[\"Genre\"] = df[\"Genre\"].apply(lambda x: x[1:-1].split(\", \"))\n",
        "df[\"Producer\"] = df[\"Producer\"].apply(lambda x: x[1:-1].split(\", \"))\n",
        "df[\"Studio\"] = df[\"Studio\"].apply(lambda x: x[1:-1].split(\", \"))\n",
        "\n",
        "# Use Word2Vec to vectorize the genre, producer and studio columns\n",
        "model_genre = Word2Vec(df[\"Genre\"], size=5, window=5, min_count=1)\n",
        "model_producer = Word2Vec(df[\"Producer\"], size=5, window=5, min_count=1)\n",
        "model_studio = Word2Vec(df[\"Studio\"], size=5, window=5, min_count=1)\n",
        "\n",
        "# Get the vector representations of the genres, producers, and studios\n",
        "df[\"Genre\"] = df[\"Genre\"].apply(lambda x: np.mean([model_genre.wv[g] for g in x], axis=0))\n",
        "df[\"Producer\"] = df[\"Producer\"].apply(lambda x: np.mean([model_producer.wv[p] for p in x], axis=0))\n",
        "df[\"Studio\"] = df[\"Studio\"].apply(lambda x: np.mean([model_studio.wv[s] for s in x], axis=0))\n",
        "\n",
        "#convert each list of arrays into a 2D numpy array\n",
        "df[\"Genre\"] = np.vstack(df[\"Genre\"].to_numpy())\n",
        "df[\"Producer\"] = np.vstack(df[\"Producer\"].to_numpy())\n",
        "df[\"Studio\"] = np.vstack(df[\"Studio\"].to_numpy())\n",
        "\n",
        "\n",
        "\n",
        "# Convert the text data into numerical representations\n",
        "vectorizer = TfidfVectorizer()\n",
        "title_vectors = vectorizer.fit_transform(df[\"Title\"])\n",
        "df[\"Title\"] = title_vectors.getnnz(axis=1)\n",
        "\n",
        "synopsis_vectors = vectorizer.fit_transform(df[\"Synopsis\"])\n",
        "df[\"Synopsis\"] = synopsis_vectors.getnnz(axis=1)\n",
        "\n",
        "#manage the type column that is a categorical feature\n",
        "le = LabelEncoder()\n",
        "df[\"Type\"] = le.fit_transform(df[\"Type\"])\n",
        "\n",
        "# Bin the target variable into 5 categorical bins\n",
        "df['Rating'] = pd.cut(df['Rating'], bins=[0, 2, 4, 6, 8, 10], labels=[1, 2, 3, 4, 5], include_lowest=True)\n",
        "# Convert the binned target variable into categorical data\n",
        "df['Rating'] = df['Rating'].astype('category')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Otzf-Dka6A8z",
        "outputId": "27c7827b-18df-4ae7-dcb5-d4c674893f5a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.base_any2vec:consider setting layer size to a multiple of 4 for greater performance\n",
            "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
            "WARNING:gensim.models.base_any2vec:consider setting layer size to a multiple of 4 for greater performance\n",
            "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
            "WARNING:gensim.models.base_any2vec:consider setting layer size to a multiple of 4 for greater performance\n",
            "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 635
        },
        "id": "7OQpiHuW7JkX",
        "outputId": "db0cf308-7b62-4706-8838-d1935f7e3e94"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Anime_id  Title     Genre  Synopsis  Type  Producer    Studio Rating  \\\n",
              "0         1      2  0.196188       132     5  0.310667  0.077610      5   \n",
              "1         5      5  0.200861       110     0  0.201675  0.084191      5   \n",
              "2         6      1  0.192712       124     5  0.141035 -0.019045      5   \n",
              "3         7      3  0.220728        59     5  0.310667  0.077610      4   \n",
              "5        15      2  0.211788       113     5  0.220687 -0.046597      5   \n",
              "\n",
              "   ScoredBy  Popularity   Members  Episodes    Source  \\\n",
              "0  363889.0        39.0  704490.0      26.0  Original   \n",
              "1  111187.0       475.0  179899.0       1.0  Original   \n",
              "2  197451.0       158.0  372709.0      26.0     Manga   \n",
              "3   31875.0      1278.0   74889.0      26.0  Original   \n",
              "5   48765.0       888.0  106468.0     145.0     Manga   \n",
              "\n",
              "                         Aired  \\\n",
              "0  Apr 3, 1998 to Apr 24, 1999   \n",
              "1                  Sep 1, 2001   \n",
              "2  Apr 1, 1998 to Sep 30, 1998   \n",
              "3  Jul 2, 2002 to Dec 24, 2002   \n",
              "5  Apr 6, 2005 to Mar 19, 2008   \n",
              "\n",
              "                                                Link  \n",
              "0       https://myanimelist.net/anime/1/Cowboy_Bebop  \n",
              "1  https://myanimelist.net/anime/5/Cowboy_Bebop__...  \n",
              "2             https://myanimelist.net/anime/6/Trigun  \n",
              "3  https://myanimelist.net/anime/7/Witch_Hunter_R...  \n",
              "5      https://myanimelist.net/anime/15/Eyeshield_21  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8d376985-0d64-4b73-a3c7-3aca35b26075\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Anime_id</th>\n",
              "      <th>Title</th>\n",
              "      <th>Genre</th>\n",
              "      <th>Synopsis</th>\n",
              "      <th>Type</th>\n",
              "      <th>Producer</th>\n",
              "      <th>Studio</th>\n",
              "      <th>Rating</th>\n",
              "      <th>ScoredBy</th>\n",
              "      <th>Popularity</th>\n",
              "      <th>Members</th>\n",
              "      <th>Episodes</th>\n",
              "      <th>Source</th>\n",
              "      <th>Aired</th>\n",
              "      <th>Link</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0.196188</td>\n",
              "      <td>132</td>\n",
              "      <td>5</td>\n",
              "      <td>0.310667</td>\n",
              "      <td>0.077610</td>\n",
              "      <td>5</td>\n",
              "      <td>363889.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>704490.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>Original</td>\n",
              "      <td>Apr 3, 1998 to Apr 24, 1999</td>\n",
              "      <td>https://myanimelist.net/anime/1/Cowboy_Bebop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>0.200861</td>\n",
              "      <td>110</td>\n",
              "      <td>0</td>\n",
              "      <td>0.201675</td>\n",
              "      <td>0.084191</td>\n",
              "      <td>5</td>\n",
              "      <td>111187.0</td>\n",
              "      <td>475.0</td>\n",
              "      <td>179899.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Original</td>\n",
              "      <td>Sep 1, 2001</td>\n",
              "      <td>https://myanimelist.net/anime/5/Cowboy_Bebop__...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>0.192712</td>\n",
              "      <td>124</td>\n",
              "      <td>5</td>\n",
              "      <td>0.141035</td>\n",
              "      <td>-0.019045</td>\n",
              "      <td>5</td>\n",
              "      <td>197451.0</td>\n",
              "      <td>158.0</td>\n",
              "      <td>372709.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>Manga</td>\n",
              "      <td>Apr 1, 1998 to Sep 30, 1998</td>\n",
              "      <td>https://myanimelist.net/anime/6/Trigun</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>0.220728</td>\n",
              "      <td>59</td>\n",
              "      <td>5</td>\n",
              "      <td>0.310667</td>\n",
              "      <td>0.077610</td>\n",
              "      <td>4</td>\n",
              "      <td>31875.0</td>\n",
              "      <td>1278.0</td>\n",
              "      <td>74889.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>Original</td>\n",
              "      <td>Jul 2, 2002 to Dec 24, 2002</td>\n",
              "      <td>https://myanimelist.net/anime/7/Witch_Hunter_R...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>15</td>\n",
              "      <td>2</td>\n",
              "      <td>0.211788</td>\n",
              "      <td>113</td>\n",
              "      <td>5</td>\n",
              "      <td>0.220687</td>\n",
              "      <td>-0.046597</td>\n",
              "      <td>5</td>\n",
              "      <td>48765.0</td>\n",
              "      <td>888.0</td>\n",
              "      <td>106468.0</td>\n",
              "      <td>145.0</td>\n",
              "      <td>Manga</td>\n",
              "      <td>Apr 6, 2005 to Mar 19, 2008</td>\n",
              "      <td>https://myanimelist.net/anime/15/Eyeshield_21</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8d376985-0d64-4b73-a3c7-3aca35b26075')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8d376985-0d64-4b73-a3c7-3aca35b26075 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8d376985-0d64-4b73-a3c7-3aca35b26075');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Split the data into training and testing sets\n",
        "X = df[[\"Title\", \"Genre\", \"Synopsis\", \"Type\", \"Producer\", \"Studio\"]]\n",
        "y = df[\"Rating\"]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train the random forest classifier on the training set\n",
        "model = RandomForestClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model on the testing set\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvvcWESH7LMo",
        "outputId": "d6ac8c7d-a8a7-4d64-c8f5-03c61343a77b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7857142857142857\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df3 = pd.read_csv(\"Anime_data.csv\")\n",
        "df3.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpRBIqepMWJ_",
        "outputId": "052e5b03-5242-4f7b-ca9c-8dd2bce61df8"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Anime_id        int64\n",
              "Title          object\n",
              "Genre          object\n",
              "Synopsis       object\n",
              "Type           object\n",
              "Producer       object\n",
              "Studio         object\n",
              "Rating        float64\n",
              "ScoredBy      float64\n",
              "Popularity    float64\n",
              "Members       float64\n",
              "Episodes      float64\n",
              "Source         object\n",
              "Aired          object\n",
              "Link           object\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ast\n",
        "new_data = {\n",
        "    'Title': [\"My Hero Academia Season 4\", \"Attack on Titan Season 4\", \"FullMetal Alchemist: Brotherhood\"],\n",
        "    'Genre': [\"Action, Adventure, Superhero\", \"Action, Drama, Fantasy\", \"Adventure, Drama, Fantasy, Science fiction\"],\n",
        "    'Synopsis': [\"The story follows a young boy named Izuku Midoriya who dreams of becoming a hero in a world where most people possess powers known as Quirks. Despite being born without a Quirk, he is scouted by the world's greatest hero and enrolls in a school for professional heroes.\",                \"Several hundred years ago, humans were nearly exterminated by Titans. Titans are typically several stories tall, and seem to have no intelligence, devouring human beings and other creatures on sight. A small percentage of humanity survived by walling themselves in a city protected by extremely high walls, even taller than the biggest of Titans.\",                \"The story is set in a fictional universe in which alchemy is one of the most advanced scientific techniques known to man. It follows two alchemist brothers named Edward and Alphonse Elric who, after a failed attempt to bring their deceased mother back to life using alchemy, set out on a journey to find the Philosopher's Stone, hoping to restore their bodies to their original forms.\"],\n",
        "    'Type': [\"TV\", \"TV\", \"TV\"],\n",
        "    'Producer': [\"Funimation, MBS, Dentsu\", \"Wit Studio, Hajime Isayama, Production I.G\", \"Aniplex, Square Enix, Mainichi Broadcasting System\"],\n",
        "    'Studio': [\"Bones, MBS\", \"Wit Studio, Production I.G\", \"Aniplex, Bones\"],\n",
        "}\n",
        "\n",
        "for key, value in new_data.items():\n",
        "    if key in [\"Genre\", \"Producer\", \"Studio\"]:\n",
        "        for i in range(len(value)):\n",
        "            new_data[key][i] = value[i].split(\", \")\n",
        "    \n",
        "new_df = pd.DataFrame(new_data)\n",
        "\n",
        "\n",
        "# Get the vector representations of the genres, producers, and studios using the previously trained Word2Vec models\n",
        "new_df[\"Genre\"] = new_df[\"Genre\"].apply(lambda x: np.mean([model_genre.wv[g] for g in x], axis=0))\n",
        "new_df[\"Producer\"] = new_df[\"Producer\"].apply(lambda x: np.mean([model_producer.wv[p] for p in x], axis=0))\n",
        "new_df[\"Studio\"] = new_df[\"Studio\"].apply(lambda x: np.mean([model_studio.wv[s] for s in x], axis=0))\n",
        "\n",
        "#convert each list of arrays into a 2D numpy array\n",
        "new_df[\"Genre\"] = np.vstack(new_df[\"Genre\"].to_numpy())\n",
        "new_df[\"Producer\"] = np.vstack(new_df[\"Producer\"].to_numpy())\n",
        "new_df[\"Studio\"] = np.vstack(new_df[\"Studio\"].to_numpy())\n",
        "\n",
        "\n",
        "# Convert the text data into numerical representations\n",
        "title_vectors = vectorizer.transform(new_df[\"Title\"])\n",
        "new_df[\"Title\"] = title_vectors.getnnz(axis=1)\n",
        "\n",
        "synopsis_vectors = vectorizer.transform(new_df[\"Synopsis\"])\n",
        "new_df[\"Synopsis\"] = synopsis_vectors.getnnz(axis=1)\n",
        "\n",
        "#manage the type column that is a categorical feature\n",
        "new_df[\"Type\"] = le.transform(new_df[\"Type\"])\n",
        "\n",
        "# Bin the target variable into 5 categorical bins\n",
        "new_df['Rating'] = pd.cut(new_df['Rating'], bins=[0, 2, 4, 6, 8, 10], labels=[1, 2, 3, 4, 5], include_lowest=True)\n",
        "# Convert the binned target variable into categorical data\n",
        "new_df['Rating'] = new_df['Rating'].astype('category')\n",
        "\n",
        "\n",
        "# Get the input features for the new data\n",
        "new_X = new_df[[\"Title\", \"Genre\", \"Synopsis\", \"Type\", \"Producer\", \"Studio\"]]\n",
        "\n",
        "\n",
        "# Use the trained model to make predictions on the new data\n",
        "new_y_pred = model.predict(new_X)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "kyRmDUnFH1CQ",
        "outputId": "7e281d49-d062-49bf-c483-3b5d3150ea54"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-0ae4a0625995>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# Get the vector representations of the genres, producers, and studios using the previously trained Word2Vec models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mnew_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Genre\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Genre\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_genre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0mnew_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Producer\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Producer\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_producer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mnew_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Studio\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Studio\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_studio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4355\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4356\u001b[0m         \"\"\"\n\u001b[0;32m-> 4357\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mSeriesApply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4359\u001b[0m     def _reduce(\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1041\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1043\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1044\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 \u001b[0;31m# List[Union[Callable[..., Any], str]]]]]\"; expected\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m                 \u001b[0;31m# \"Callable[[Any], Any]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m                 mapped = lib.map_infer(\n\u001b[0m\u001b[1;32m   1099\u001b[0m                     \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-0ae4a0625995>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# Get the vector representations of the genres, producers, and studios using the previously trained Word2Vec models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mnew_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Genre\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Genre\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_genre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0mnew_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Producer\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Producer\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_producer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mnew_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Studio\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Studio\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_studio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-0ae4a0625995>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# Get the vector representations of the genres, producers, and studios using the previously trained Word2Vec models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mnew_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Genre\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Genre\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_genre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0mnew_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Producer\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Producer\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_producer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mnew_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Studio\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Studio\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_studio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, entities)\u001b[0m\n\u001b[1;32m    335\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentities\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m             \u001b[0;31m# allow calls like trained_model['office'], as a shorthand for trained_model[['office']]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentity\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mentity\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentities\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mget_vector\u001b[0;34m(self, word)\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwords_closer_than\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mword_vec\u001b[0;34m(self, word, use_norm)\u001b[0m\n\u001b[1;32m    450\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"word '%s' not in vocabulary\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"word 'Action' not in vocabulary\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_data = {\n",
        "    'Title': [\"My Hero Academia Season 4\", \"Attack on Titan Season 4\", \"FullMetal Alchemist: Brotherhood\"],\n",
        "    'Genre': [\"Action, Adventure, Superhero\", \"Action, Drama, Fantasy\", \"Adventure, Drama, Fantasy, Science fiction\"],\n",
        "    'Synopsis': [\"The story follows a young boy named Izuku Midoriya who dreams of becoming a hero in a world where most people possess powers known as Quirks. Despite being born without a Quirk, he is scouted by the world's greatest hero and enrolls in a school for professional heroes.\",                \"Several hundred years ago, humans were nearly exterminated by Titans. Titans are typically several stories tall, and seem to have no intelligence, devouring human beings and other creatures on sight. A small percentage of humanity survived by walling themselves in a city protected by extremely high walls, even taller than the biggest of Titans.\",                \"The story is set in a fictional universe in which alchemy is one of the most advanced scientific techniques known to man. It follows two alchemist brothers named Edward and Alphonse Elric who, after a failed attempt to bring their deceased mother back to life using alchemy, set out on a journey to find the Philosopher's Stone, hoping to restore their bodies to their original forms.\"],\n",
        "    'Type': [\"TV\", \"TV\", \"TV\"],\n",
        "    'Producer': [\"Funimation, MBS, Dentsu\", \"Wit Studio, Hajime Isayama, Production I.G\", \"Aniplex, Square Enix, Mainichi Broadcasting System\"],\n",
        "    'Studio': [\"Bones, MBS\", \"Wit Studio, Production I.G\", \"Aniplex, Bones\"],\n",
        "}\n",
        "\n",
        "new_df = pd.DataFrame(new_data)\n",
        "def convert_to_list(value):\n",
        "    return value.split(\", \")\n",
        "\n",
        "new_df[\"Genre\"] = new_df[\"Genre\"].apply(convert_to_list)\n",
        "new_df[\"Producer\"] = new_df[\"Producer\"].apply(convert_to_list)\n",
        "new_df[\"Studio\"] = new_df[\"Studio\"].apply(convert_to_list)\n",
        "\n",
        "new_df.head()\n"
      ],
      "metadata": {
        "id": "2sYBWDknKAgw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a=\"bonjour,hello,morning\"\n",
        "print(a.split(\",\"))"
      ],
      "metadata": {
        "id": "tf1Y7hu9qgYX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}